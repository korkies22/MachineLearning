{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos utilizando readcsv de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el archivo con los datos\n",
    "data_pulsar = pd.read_csv('./data/HTRU_2.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan los datos en \"x\" y \"y\". Se normaliza x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable dependiente es la última columna, las independientes son las anteriores.\n",
    "#Se normaliza las independientes y se convierte nuevamente en un DataFrame de Pandas\n",
    "x= pd.DataFrame.from_records(preprocessing.normalize(data_pulsar.iloc[:,0:8]))\n",
    "y= data_pulsar.iloc[:,8:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se parten los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el archivo para entrenamiento y test. Se reserven 10000 datos para test\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 10000, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrain,yTrain], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escogen aleatoriamente diferentes tamaños de datos para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De estos datos concatenados se escogen aleatoriamente 100,500,1000 y 5000 para diferentes modelos. \n",
    "#De aquí se vuelven a separar en x y y\n",
    "dataTrain1= newData.sample(100, random_state = 0)\n",
    "xTrain1= dataTrain1.iloc[:,0:8]\n",
    "yTrain1= dataTrain1.iloc[:,8]\n",
    "dataTrain2= newData.sample(500, random_state = 0)\n",
    "xTrain2= dataTrain2.iloc[:,0:8]\n",
    "yTrain2= dataTrain2.iloc[:,8]\n",
    "dataTrain3= newData.sample(1000, random_state = 0)\n",
    "xTrain3= dataTrain3.iloc[:,0:8]\n",
    "yTrain3= dataTrain3.iloc[:,8]\n",
    "dataTrain4= newData.sample(5000, random_state = 0)\n",
    "xTrain4= dataTrain4.iloc[:,0:8]\n",
    "yTrain4= dataTrain4.iloc[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3471877  -0.12043274  0.10001708  0.50525963  0.79415348  0.90285417\n",
      "  -0.08293925 -1.62638016]]\n",
      "[[-3.08949271  0.5681149   0.44026083  2.24643966  1.24674773  2.99543923\n",
      "   0.01975481 -2.03796584]]\n",
      "[[-3.64709138  2.04694934  0.70306718  3.01305858  0.32916592  4.24427233\n",
      "   0.30359388 -1.77718205]]\n",
      "[[-5.44700152  4.90003648  1.77036411  6.86075577 -1.17970812  7.49200128\n",
      "   1.36362609 -1.23668302]]\n"
     ]
    }
   ],
   "source": [
    "#Se entrenan los modelos respectivos utilizando la librería de regresión logística de skelearn\n",
    "logisticRegr1 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr1.fit(xTrain1, yTrain1)\n",
    "print(logisticRegr1.coef_)\n",
    "logisticRegr2 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr2.fit(xTrain2, yTrain2)\n",
    "print(logisticRegr2.coef_)\n",
    "logisticRegr3 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr3.fit(xTrain3, yTrain3)\n",
    "print(logisticRegr3.coef_)\n",
    "logisticRegr4 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr4.fit(xTrain4, yTrain4)\n",
    "print(logisticRegr4.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye una función de éxito para evaluar el modelo.\n",
    "Esta función es la que será utilizada para evaluar el modelo con descenso de gradiente también y así poder comprar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de función sigmoide para usarse posteriormente\n",
    "def sigmoid(x):\n",
    "     return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que calcula el error final de clasificación. \n",
    "#Como tal lo que devuelve es el porcentaje de datos exitosamente clasificados\n",
    "def calc_exito(nX,nY,w):\n",
    "    a=nX.to_numpy()\n",
    "    y=nY.to_numpy()\n",
    "    x = np.ones((a.shape[0],a.shape[1]+1))\n",
    "    x[:,:-1] = a\n",
    "    wNumber= x.shape[1]\n",
    "    numData= x.shape[0]\n",
    "    err=0\n",
    "    for i in range(0, numData):\n",
    "        prob1=sigmoid((x[i]*w).sum())\n",
    "        #El porcentaje de error aumenta si se clasificó mal tanto como 1 cómo como 0\n",
    "        if prob1>0.5 and y[i]==0:\n",
    "            err=err+1\n",
    "        #Se asigna el 0.5 como valor inclusivo hacia el 0 dado que el porcentaje de 0's es mucho mayor.\n",
    "        if prob1<=0.5 and y[i]==1:\n",
    "            err=err+1\n",
    "    return 1-(err/numData)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúan los datos con la función score de skelearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 1\n",
    "score1 = logisticRegr1.score(xTest, yTest)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 2\n",
    "score2 = logisticRegr2.score(xTest, yTest)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9618\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 3\n",
    "score3 = logisticRegr3.score(xTest, yTest)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 4\n",
    "score4 = logisticRegr4.score(xTest, yTest)\n",
    "print(score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo con la función personalizada de éxito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144\n"
     ]
    }
   ],
   "source": [
    "ws=logisticRegr1.coef_[0]\n",
    "\n",
    "score1 = calc_exito(xTest, yTest,np.append(ws,logisticRegr1.intercept_))\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576\n"
     ]
    }
   ],
   "source": [
    "ws=logisticRegr2.coef_[0]\n",
    "\n",
    "score2 = calc_exito(xTest, yTest,np.append(ws,logisticRegr2.intercept_))\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9618\n"
     ]
    }
   ],
   "source": [
    "ws=logisticRegr3.coef_[0]\n",
    "\n",
    "score3 = calc_exito(xTest, yTest,np.append(ws,logisticRegr3.intercept_))\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695\n"
     ]
    }
   ],
   "source": [
    "ws=logisticRegr4.coef_[0]\n",
    "\n",
    "score4 = calc_exito(xTest, yTest,np.append(ws,logisticRegr4.intercept_))\n",
    "print(score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Como se puede observar, todos los modelos tuvieron menos de 10% de error, lo que implicaría que los datos se comportan de manera altamente lineal. A medida que aumenta el número de dato se observa que aumenta la tasa de éxito, lo cual concuerda con la teoría. Además, se observa que ambas funciones de error utilizadas dan como resultado el mismo valor, por lo que esta función personalizada puede ser usada para evaluar el modelo hecho a mano en el reto 3.\n",
    "Sin embargo, se debe tener en cuenta que la mayoría de valores yi de los datos son 0. Por lo cual un modelo que tiende a clasificar los datos como 0 posiblemente dé mejores resultados. Aunque se debe tener en cuenta que la tasa de éxito fue de más de 90% con suficientes datos, que es lo que pasaría si realmente los datos de entrenamiento y validación se escogen de manera aleatoria y el modelo solamente indicara 0 para cualquier dato."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
