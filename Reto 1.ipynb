{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el archivo con los datos\n",
    "data_pulsar = pd.read_csv('./data/HTRU_2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable dependiente es la última columna, las independientes son las anteriores\n",
    "x= data_pulsar.iloc[:,0:8]\n",
    "y= data_pulsar.iloc[:,8:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el archivo para entrenamiento y test. Se reserven 10000 datos para test\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 10000, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrain,yTrain], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De estos datos concatenados se escogen aleatoriamente 100,500,1000 y 5000 para diferentes modelos. \n",
    "#De aquí se vuelven a separar en x y y\n",
    "dataTrain1= newData.sample(100)\n",
    "xTrain1= dataTrain1.iloc[:,0:8]\n",
    "yTrain1= dataTrain1.iloc[:,8]\n",
    "dataTrain2= newData.sample(500)\n",
    "xTrain2= dataTrain2.iloc[:,0:8]\n",
    "yTrain2= dataTrain2.iloc[:,8]\n",
    "dataTrain3= newData.sample(1000)\n",
    "xTrain3= dataTrain3.iloc[:,0:8]\n",
    "yTrain3= dataTrain3.iloc[:,8]\n",
    "dataTrain4= newData.sample(5000)\n",
    "xTrain4= dataTrain4.iloc[:,0:8]\n",
    "yTrain4= dataTrain4.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08744175  0.18656167  0.46599125  0.53395604 -0.03525458  0.01341955\n",
      "  -0.5904432   0.01422778]]\n",
      "[[-0.00757564  0.01549698  2.43642026 -0.03275998 -0.02476578 -0.01149915\n",
      "  -0.62079579  0.01578822]]\n",
      "[[-0.05357939 -0.0120126   2.18532723 -0.02983895 -0.01292476  0.05705695\n",
      "   0.31935792 -0.02109728]]\n",
      "[[ 1.90309380e-03 -5.38818277e-02  4.69240537e+00 -4.54694620e-01\n",
      "  -3.04482171e-02  2.78269869e-02 -2.73207172e-01  5.88562102e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Se entrenan los modelos respectivos utilizando la librería de regresión logística de skelearn\n",
    "logisticRegr1 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr1.fit(xTrain1, yTrain1)\n",
    "print(logisticRegr1.coef_)\n",
    "logisticRegr2 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr2.fit(xTrain2, yTrain2)\n",
    "print(logisticRegr2.coef_)\n",
    "logisticRegr3 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr3.fit(xTrain3, yTrain3)\n",
    "print(logisticRegr3.coef_)\n",
    "logisticRegr4 = LogisticRegression(solver='liblinear')\n",
    "logisticRegr4.fit(xTrain4, yTrain4)\n",
    "print(logisticRegr4.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 1\n",
    "score1 = logisticRegr1.score(xTest, yTest)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 2\n",
    "score2 = logisticRegr2.score(xTest, yTest)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 3\n",
    "score3 = logisticRegr3.score(xTest, yTest)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 4\n",
    "score4 = logisticRegr4.score(xTest, yTest)\n",
    "print(score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Como se puede observar, todos los modelos tuvieron menos de 3% de error, lo que implicaría que los datos se comportan de manera altamente lineal. A medida que aumenta el número de dato se observa que aumenta la tasa de éxito, lo cual concuerda con la teoría.\n",
    "Sin embargo, se debe tener en cuenta que la mayoría de valores yi de los datos son 0. Por lo cual un modelo que tiende a clasificar los datos como 0 posiblemente dé mejores resultados. Aunque se debe tener en cuenta que la tasa de éxito fue de más de 90%, que es lo que pasaría si realmente los datos de entrenamiento y validación se escogen de manera aleatoria y el modelo solamente indicara 0 para cualquier dato.\n",
    "Se observa finalmente que el modelo 2 y el modelo 3 tienen una similitud en cuanto a sus parámetros, aunque el modelo 1 es más parecido al modelo 2 respecto a su tasa de éxito de clasificación y el modelo 3 es más similar al 4 respecto a lo mismo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
