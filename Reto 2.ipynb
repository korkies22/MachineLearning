{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el archivo con los datos\n",
    "data_wine = pd.read_csv('./data/winequality-white.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable dependiente es la última columna, las independientes son las anteriores\n",
    "x= data_wine.iloc[:,0:11]\n",
    "y= data_wine.iloc[:,11:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el archivo para entrenamiento y test. Se reserven 2000 datos para test\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 2000, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrain,yTrain], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De estos datos concatenados se escogen aleatoriamente 100,1000 y 2898 para diferentes modelos. \n",
    "#De aquí se vuelven a separar en x y y\n",
    "dataTrain1= newData.sample(100)\n",
    "xTrain1= dataTrain1.iloc[:,0:11]\n",
    "yTrain1= dataTrain1.iloc[:,11]\n",
    "dataTrain2= newData.sample(1000)\n",
    "xTrain2= dataTrain2.iloc[:,0:11]\n",
    "yTrain2= dataTrain2.iloc[:,11]\n",
    "dataTrain3= newData.sample(2898)\n",
    "xTrain3= dataTrain3.iloc[:,0:11]\n",
    "yTrain3= dataTrain3.iloc[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.21788382e-01 -2.59380208e+00 -1.10188622e-01  9.25383021e-02\n",
      "  1.28918768e+00 -1.43579702e-03  1.20763540e-03 -1.80935120e+02\n",
      "  5.76651336e-01  8.12564464e-01  2.01603572e-01]\n",
      "[ 3.36484714e-03 -1.81385881e+00  1.52574830e-01  6.92809251e-02\n",
      "  4.23214541e-01  7.85876075e-03 -8.70553703e-05 -1.37903233e+02\n",
      "  6.84418465e-01  5.55963048e-01  2.24746268e-01]\n",
      "[ 9.14561128e-02 -1.72938062e+00  2.46667088e-02  8.53783046e-02\n",
      " -7.27676750e-01  6.66155786e-03 -3.13733017e-04 -1.78769595e+02\n",
      "  8.20980765e-01  6.12329914e-01  1.46010129e-01]\n"
     ]
    }
   ],
   "source": [
    "#Se entrenan los modelos respectivos utilizando la librería de regresión lineal de skelearn\n",
    "linearRegr1 = LinearRegression()\n",
    "linearRegr1.fit(xTrain1, yTrain1)\n",
    "print(linearRegr1.coef_)\n",
    "linearRegr2 = LinearRegression()\n",
    "linearRegr2.fit(xTrain2, yTrain2)\n",
    "print(linearRegr2.coef_)\n",
    "linearRegr3 = LinearRegression()\n",
    "linearRegr3.fit(xTrain3, yTrain3)\n",
    "print(linearRegr3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2656646191296127\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 1\n",
    "score1 = linearRegr1.score(xTest, yTest)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24806654857047106\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 2\n",
    "score2 = linearRegr2.score(xTest, yTest)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2559538292482815\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 3\n",
    "score3 = linearRegr3.score(xTest, yTest)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "Se puede observar que en todos los casos el R^2 es muy bajo, ninguno llegó a 0.3. También se observa que a medida que el número de datos aumenta, aumenta este valor de R^2. El bajo resultado puede ser explicado con que el modelo no es lineal. También cabe la posibilidad de que se necesiten más datos, pero la diferencia de R^2 entre el modelo con 1000 datos y el modelo con 2800 datos no es significativa. Los modelos tienen ordenes de magnitud similares para cada uno de sus parámetros. El modelo con mayor R^2 es el primero, lo cual puede explicarse con el hecho que aunque tenga menores datos de entrenamiento, si los datos no se comportan de manera lineal entonces este puede que de alguna manera se ajuste mejor a los datos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
