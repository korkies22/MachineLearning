{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos utilizando readcsv de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el archivo con los datos\n",
    "data_wine = pd.read_csv('./data/winequality-white.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan los datos en \"x\" y \"y\". Se normaliza x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable dependiente es la última columna, las independientes son las anteriores\n",
    "x= pd.DataFrame.from_records(preprocessing.normalize(data_wine.iloc[:,0:11]))\n",
    "y= data_wine.iloc[:,11:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se parten los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el archivo para entrenamiento y test. Se reserven 2000 datos para test\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 2000, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrain,yTrain], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escogen aleatoriamente diferentes tamaños de datos para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De estos datos concatenados se escogen aleatoriamente 100,1000 y 2898 para diferentes modelos. \n",
    "#De aquí se vuelven a separar en x y y\n",
    "dataTrain1= newData.sample(100)\n",
    "xTrain1= dataTrain1.iloc[:,0:11]\n",
    "yTrain1= dataTrain1.iloc[:,11]\n",
    "dataTrain2= newData.sample(1000)\n",
    "xTrain2= dataTrain2.iloc[:,0:11]\n",
    "yTrain2= dataTrain2.iloc[:,11]\n",
    "dataTrain3= newData.sample(2898)\n",
    "xTrain3= dataTrain3.iloc[:,0:11]\n",
    "yTrain3= dataTrain3.iloc[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -8.34583658  -75.22397859  -99.83683038    2.64998917 -632.43264047\n",
      "    8.53146768   24.37283061 -202.51119805  -23.23141053  173.27578873\n",
      "   34.04441192]\n",
      "[  -3.63923745 -175.56099926   -1.48660515    3.14722658 -113.37086007\n",
      "    4.90142432   13.57949249 -482.77584028   33.01311283   54.3193092\n",
      "   40.4656056 ]\n",
      "[   0.79107365 -184.11604285  -10.73052733    2.83914324 -247.22059891\n",
      "    5.33019901   14.09951252 -486.67706273   37.80892092   53.16384432\n",
      "   38.05965421]\n"
     ]
    }
   ],
   "source": [
    "#Se entrenan los modelos respectivos utilizando la librería de regresión lineal de skelearn\n",
    "linearRegr1 = LinearRegression()\n",
    "linearRegr1.fit(xTrain1, yTrain1)\n",
    "print(linearRegr1.coef_)\n",
    "linearRegr2 = LinearRegression()\n",
    "linearRegr2.fit(xTrain2, yTrain2)\n",
    "print(linearRegr2.coef_)\n",
    "linearRegr3 = LinearRegression()\n",
    "linearRegr3.fit(xTrain3, yTrain3)\n",
    "print(linearRegr3.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúan los datos con la función score de skelearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12690339475494627\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 1\n",
    "score1 = linearRegr1.score(xTest, yTest)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24627334058742112\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 2\n",
    "score2 = linearRegr2.score(xTest, yTest)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24522803680952607\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 3\n",
    "score3 = linearRegr3.score(xTest, yTest)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye una función de éxito para evaluar el modelo.\n",
    "Esta función es la que será utilizada para evaluar el modelo con descenso de gradiente también y así poder comprar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular R^2 como 1-u/v, similar a como lo calcula sklearn para validar\n",
    "def calc_r2(nX,nY,w):\n",
    "    a=nX.to_numpy()\n",
    "    y=nY.to_numpy()\n",
    "    x = np.ones((a.shape[0],a.shape[1]+1))\n",
    "    x[:,:-1] = a\n",
    "    wNumber= x.shape[1]\n",
    "    numData= x.shape[0]\n",
    "    u=0\n",
    "    v=0\n",
    "    #ym es la media de todos los y\n",
    "    ym= y.mean()\n",
    "    err=0\n",
    "    for i in range(0, numData):\n",
    "        xi=x[i]\n",
    "        yi=y[i]\n",
    "        yp=(xi*w).sum()\n",
    "        #u es la suma de cuadrados residuales (yi - yPredecido)\n",
    "        u+=(yi-yp)**2\n",
    "        #u es la suma total de cuadrados (yi - yMedia)\n",
    "        v+=(yi-ym)**2\n",
    "    r2=1-(u/v)\n",
    "    return r2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo con la función personalizada de éxito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12690339]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr1.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r21 = calc_r2(xTest, yTest,np.append(ws,linearRegr1.intercept_))\n",
    "print(r21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24627334]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr2.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r22 = calc_r2(xTest, yTest,np.append(ws,linearRegr2.intercept_))\n",
    "print(r22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24522804]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr3.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r23 = calc_r2(xTest, yTest,np.append(ws,linearRegr3.intercept_))\n",
    "print(r23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "Se puede observar que en todos los casos el R^2 es muy bajo, ninguno llegó a 0.3. También se observa que a medida que el número de datos aumenta, aumenta este valor de R^2. El resultado de la función de R^2 propia arroja un valor similar a la de sklearn, por lo tanto esta puede ser utilizada en el reto 4 para calcular el error con el modelo con descenso de gradiente.\n",
    "El bajo resultado puede ser explicado con que el modelo no es lineal. También cabe la posibilidad de que se necesiten más datos, pero la diferencia de R^2 entre el modelo con 1000 datos y el modelo con 2800 datos no es significativa. Los modelos tienen ordenes de magnitud similares para cada uno de sus parámetros. El modelo con mayor R^2 es el primero, lo cual puede explicarse con el hecho que aunque tenga menores datos de entrenamiento, si los datos no se comportan de manera lineal entonces este puede que de alguna manera se ajuste mejor a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
