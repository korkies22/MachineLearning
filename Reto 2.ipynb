{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los datos utilizando readcsv de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el archivo con los datos\n",
    "data_wine = pd.read_csv('./data/winequality-white.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan los datos en \"x\" y \"y\". Se normaliza x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable dependiente es la última columna, las independientes son las anteriores\n",
    "x= pd.DataFrame.from_records(preprocessing.normalize(data_wine.iloc[:,0:11]))\n",
    "y= data_wine.iloc[:,11:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se parten los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el archivo para entrenamiento y test. Se reserven 2000 datos para test\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 2000, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se concatenan los datos de test\n",
    "newData= pd.concat([xTrain,yTrain], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escogen aleatoriamente diferentes tamaños de datos para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De estos datos concatenados se escogen aleatoriamente 100,1000 y 2898 para diferentes modelos. \n",
    "#De aquí se vuelven a separar en x y y\n",
    "dataTrain1= newData.sample(100, random_state = 0)\n",
    "xTrain1= dataTrain1.iloc[:,0:11]\n",
    "yTrain1= dataTrain1.iloc[:,11]\n",
    "dataTrain2= newData.sample(1000, random_state = 0)\n",
    "xTrain2= dataTrain2.iloc[:,0:11]\n",
    "yTrain2= dataTrain2.iloc[:,11]\n",
    "dataTrain3= newData.sample(2898, random_state = 0)\n",
    "xTrain3= dataTrain3.iloc[:,0:11]\n",
    "yTrain3= dataTrain3.iloc[:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9.18043753 -297.37333753  -43.39188013    2.08983943  -38.9739378\n",
      "   11.31463224   36.4460685  -779.5933183   114.29170588  167.58647873\n",
      "   42.89160425]\n",
      "[-3.86358296e-02 -2.32120321e+02 -3.68357650e+01  3.51869418e+00\n",
      " -3.13133503e+02  7.52671803e+00  2.36929580e+01 -5.46990605e+02\n",
      "  6.10183996e+01  1.02581283e+00  4.13683096e+01]\n",
      "[   0.79107365 -184.11604285  -10.73052733    2.83914324 -247.22059891\n",
      "    5.33019901   14.09951252 -486.67706273   37.80892092   53.16384432\n",
      "   38.05965421]\n"
     ]
    }
   ],
   "source": [
    "#Se entrenan los modelos respectivos utilizando la librería de regresión lineal de skelearn\n",
    "linearRegr1 = LinearRegression()\n",
    "linearRegr1.fit(xTrain1, yTrain1)\n",
    "print(linearRegr1.coef_)\n",
    "linearRegr2 = LinearRegression()\n",
    "linearRegr2.fit(xTrain2, yTrain2)\n",
    "print(linearRegr2.coef_)\n",
    "linearRegr3 = LinearRegression()\n",
    "linearRegr3.fit(xTrain3, yTrain3)\n",
    "print(linearRegr3.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúan los datos con la función score de skelearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014844918467560753\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 1\n",
    "score1 = linearRegr1.score(xTest, yTest)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17491900838852514\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 2\n",
    "score2 = linearRegr2.score(xTest, yTest)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.245228036809525\n"
     ]
    }
   ],
   "source": [
    "#Resultado de test de modelo 3\n",
    "score3 = linearRegr3.score(xTest, yTest)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye una función de éxito para evaluar el modelo.\n",
    "Esta función es la que será utilizada para evaluar el modelo con descenso de gradiente también y así poder comprar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular R^2 como 1-u/v, similar a como lo calcula sklearn para validar\n",
    "def calc_r2(nX,nY,w):\n",
    "    a=nX.to_numpy()\n",
    "    y=nY.to_numpy()\n",
    "    x = np.ones((a.shape[0],a.shape[1]+1))\n",
    "    x[:,:-1] = a\n",
    "    wNumber= x.shape[1]\n",
    "    numData= x.shape[0]\n",
    "    u=0\n",
    "    v=0\n",
    "    #ym es la media de todos los y\n",
    "    ym= y.mean()\n",
    "    err=0\n",
    "    for i in range(0, numData):\n",
    "        xi=x[i]\n",
    "        yi=y[i]\n",
    "        yp=(xi*w).sum()\n",
    "        #u es la suma de cuadrados residuales (yi - yPredecido)\n",
    "        u+=(yi-yp)**2\n",
    "        #u es la suma total de cuadrados (yi - yMedia)\n",
    "        v+=(yi-ym)**2\n",
    "    r2=1-(u/v)\n",
    "    return r2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo con la función personalizada de éxito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01484492]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr1.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r21 = calc_r2(xTest, yTest,np.append(ws,linearRegr1.intercept_))\n",
    "print(r21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17491901]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr2.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r22 = calc_r2(xTest, yTest,np.append(ws,linearRegr2.intercept_))\n",
    "print(r22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24522804]\n"
     ]
    }
   ],
   "source": [
    "ws=linearRegr3.coef_\n",
    "#Cálculo de R^2 para el modelo 1\n",
    "r23 = calc_r2(xTest, yTest,np.append(ws,linearRegr3.intercept_))\n",
    "print(r23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "Se puede observar que en todos los casos el R^2 es muy bajo, ninguno llegó a 0.3. También se observa que a medida que el número de datos aumenta, aumenta este valor de R^2. El resultado de la función de R^2 propia arroja un valor similar a la de sklearn, por lo tanto esta puede ser utilizada en el reto 4 para calcular el error con el modelo con descenso de gradiente.\n",
    "El bajo resultado puede ser explicado con que el modelo no es lineal. Todos los modelos tienen ordenes de magnitud distintos para cada uno de sus parámetros respecto a los demás. A medida que los modelos se entrenan con más datos el R^2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
